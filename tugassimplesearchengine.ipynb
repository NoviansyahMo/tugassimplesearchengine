{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tugassimplesearchengine.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOlkoXaOn4Gy"
      },
      "source": [
        "document_1 = \"Tutorial Belajar Visual Basic 6 Dari Dasar Untuk Pemula â€“ yadishare Lanjut ke konten berbagi informasi seputar youtube, bahasa pemrograman, pengalaman dan teknologi lainnya\"\r\n",
        "document_2 = \"Python Tutorial w3schools.com LOG IN THE WORLD\\'S LARGEST WEB DEVELOPER SITE HTML CSS JAVASCRIPT SQL PYTHON PHP BOOTSTRAP HOW TO W3.CSS JQUERY JAVA MORE\"\r\n",
        "document_3 = \"Python Tutorials for Beginners Home Testing Back Agile Testing BugZilla Cucumber Database Testing ETL Testing Jmeter JIRA Back JUnit LoadRunner Manual Testing Mobile Testing\"\r\n",
        "document_4 = \"Tutorial python - Jagocoding.com Toggle navigation Tutorials Articles Snippets Search\"\r\n",
        "document_5 = \"Belajar HTML Dan CSS Lengkap Untuk Pemula +6281395777706 Kelas Premium Kelas Beasiswa Produk Digital Halaman Member Login Register Article Belajar HTML Dan CSS Belajar Javascript\"\r\n",
        "documents = [document_1, document_2, document_3, document_4, document_5]\r\n",
        "documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7yF89rrpVf"
      },
      "source": [
        "tokens = sum([word_tokenize(document) for document in documents], [])\r\n",
        "words_frequency = FreqDist(tokens)\r\n",
        "words_frequency.plot(30, cumulative = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBsTuSEloK6C"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "def normalized_term_frequency(word, document):\r\n",
        "    raw_frequency = document.count(word)\r\n",
        "    if raw_frequency == 0:\r\n",
        "        return 0\r\n",
        "    return 1 + math.log(raw_frequency)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHXcyXaVrw81"
      },
      "source": [
        "def docs_contain_word(word, documents):\r\n",
        "\tcounter = 0\r\n",
        "\tfor document in list_of_documents:\r\n",
        "\t\tif word in document:\r\n",
        "\t\t\tcounter+=1\r\n",
        "\t\r\n",
        "\treturn counter\r\n",
        "\r\n",
        "def get_vocabulary(documents):\r\n",
        "\tvocabulary = set([word for document in documents for word in document])\t\r\n",
        "\t\r\n",
        "\treturn vocabulary\r\n",
        "\r\n",
        "def inverse_document_frequency(documents, vocabulary):\r\n",
        "\r\n",
        "\tidf = {}\r\n",
        "\t\r\n",
        "\tfor word in vocabulary:\r\n",
        "\t\tcontains_word = docs_contain_word(word, documents)\r\n",
        "\t\tidf[word] = 1 + math.log(len(documents)/(contains_word))\r\n",
        "        \r\n",
        "\treturn idf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbsiYNYyr0hc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "def tf_idf(search_keys, dataframe):\r\n",
        "  \r\n",
        "\ttfidf_vectorizer = TfidfVectorizer()\r\n",
        "\ttfidf_weights_matrix = tfidf_vectorizer.fit_transform(dataframe)\r\n",
        "\tkeys_weights_matrix = tfidf_vectorizer.transform([search_keys])\r\n",
        "\t\r\n",
        "\treturn keys_weights_matrix, tfidf_weights_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQjqffXUsKmA"
      },
      "source": [
        "key, matriks = tf_idf('Belajar HTML', documents)\r\n",
        "print(matriks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL8L--cTsW6U"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\r\n",
        "\r\n",
        "def cos_similarity(search_query_weights, tfidf_weights_matrix):\r\n",
        "\t\r\n",
        "\tcosine_distance = cosine_similarity(search_query_weights, tfidf_weights_matrix)\r\n",
        "\tsimilarity_list = cosine_distance[0]\r\n",
        "  \r\n",
        "\treturn similarity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8LzmXAMsaj9"
      },
      "source": [
        "similarity_list = cos_similarity(key, matriks)\r\n",
        "print(similarity_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVbtqcOshfF"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def most_similar(similarity_list, min_talks=1):\r\n",
        "\t\r\n",
        "\tmost_similar= []\r\n",
        "  \r\n",
        "\twhile min_talks > 0:\r\n",
        "\t\ttmp_index = np.argmax(similarity_list)\r\n",
        "\t\tmost_similar.append(tmp_index)\r\n",
        "\t\tsimilarity_list[tmp_index] = 0\r\n",
        "\t\tmin_talks -= 1\r\n",
        "\r\n",
        "\treturn most_similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo0092FWsk2e"
      },
      "source": [
        "most = most_similar(similarity_list, min_talks=1)\r\n",
        "print(documents[4])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}